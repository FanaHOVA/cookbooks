{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from termcolor import colored  \n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_request(messages, tools=None, tool_choice=\"auto\", model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single data extraction\n",
    "\n",
    "You can easily extract structured data.\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_people_information\",\n",
    "            \"description\": \"Extract the information for a person. Make sure to use MM/DD/YY formatting for dates.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Name of the person to be extracted.\"\n",
    "                    },\n",
    "                    \"birthday\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Date of birth of the person to be extracted.\"\n",
    "                    },\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Location of the person to be extracted.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name, birthday, location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create these definitions using pydantic as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"Extract the information for a person. Make sure to use MM/DD/YY formatting for dates.\",\n",
      "  \"properties\": {\n",
      "    \"name\": {\n",
      "      \"description\": \"Name of the person to be extracted.\",\n",
      "      \"title\": \"Name\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"birthday\": {\n",
      "      \"description\": \"Date of birth of the person to be extracted.\",\n",
      "      \"title\": \"Birthday\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"location\": {\n",
      "      \"description\": \"Location of the person to be extracted.\",\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"name\",\n",
      "    \"birthday\",\n",
      "    \"location\"\n",
      "  ],\n",
      "  \"title\": \"extract_people_information\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class extract_people_information(BaseModel):\n",
    "    \"\"\"Extract the information for a person. Make sure to use MM/DD/YY formatting for dates.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the person to be extracted.\")\n",
    "    birthday: str = Field(description=\"Date of birth of the person to be extracted.\")\n",
    "    location: str = Field(description=\"Location of the person to be extracted.\")\n",
    "\n",
    "print(json.dumps(extract_people_information.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zKSgfhxVKx26vdhr4ZNGBnR8', function=Function(arguments='{\\n  \"name\": \"Alessio\",\\n  \"birthday\": \"08/29/1995\",\\n  \"location\": \"Rome\"\\n}', name='extract_people_information'), type='function')]))]\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"You're an assistant that summarizes the information for all people mentioned in the user messages.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"I met Alessio, a guy from Rome whose birthday is on Aug 29th and is 29 years old (we are in 2024 now). I also met Sarah who was born on the 8th of August instead and is from Milwaukee\"})\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "print(chat_response.choices)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You're an assistant that summarizes the information for all people mentioned in the user messages.\n",
      "\u001b[0m\n",
      "\u001b[32muser: I met Alessio, a guy from Rome whose birthday is on Aug 29th and is 29 years old (we are in 2024 now). I also met Sarah who was born on the 8th of August instead and is from Milwaukee\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\\n  \"name\": \"Alessio\",\\n  \"birthday\": \"08/29/1995\",\\n  \"location\": \"Rome\"\\n}', name='extract_people_information')\n",
      "\u001b[0m\n",
      "{\n",
      "  \"name\": \"Alessio\",\n",
      "  \"birthday\": \"08/29/1995\",\n",
      "  \"location\": \"Rome\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)\n",
    "\n",
    "print(assistant_message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No mention of Sarah in that message as you can see. One way to have multiple calls is defining the properties within an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"extract_people_information\",\n",
    "        \"description\": \"Extract information for multiple people. Make sure to use MM/DD/YY formatting for dates.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"people\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"name\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Name of the person to be extracted.\"\n",
    "                            },\n",
    "                            \"birthday\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Date of birth of the person to be extracted.\"\n",
    "                            },\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Location of the person to be extracted.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"name\", \"birthday\", \"location\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"people\"]\n",
    "        },\n",
    "    }\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_f6w7w6IpdSOZvFJ1JNgng0i9', function=Function(arguments='{\"people\": [{\"name\": \"Alessio\", \"birthday\": \"08/29/1995\", \"location\": \"Rome\"}, {\"name\": \"Sarah\", \"birthday\": \"08/08/??\", \"location\": \"Milwaukee\"}]}', name='extract_people_information'), type='function')]))]\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"You're an assistant that summarizes the information for all people mentioned in the user messages. You should make sure you don't miss anyone that is mentioned. There will be multiple people in each message.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"I met Alessio, a guy from Rome whose birthday is on Aug 29th and is 29 years old (we are in 2024 now). I also met Sarah who was born on the 8th of August instead and is from Milwaukee\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools, model=\"gpt-4-turbo-preview\")\n",
    "print(chat_response.choices)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You're an assistant that summarizes the information for all people mentioned in the user messages. You should make sure you don't miss anyone that is mentioned. There will be multiple people in each message.\n",
      "\u001b[0m\n",
      "\u001b[32muser: I met Alessio, a guy from Rome whose birthday is on Aug 29th and is 29 years old (we are in 2024 now). I also met Sarah who was born on the 8th of August instead and is from Milwaukee\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\"people\": [{\"name\": \"Alessio\", \"birthday\": \"08/29/1995\", \"location\": \"Rome\"}, {\"name\": \"Sarah\", \"birthday\": \"08/08/??\", \"location\": \"Milwaukee\"}]}', name='extract_people_information')\n",
      "\u001b[0m\n",
      "{\"people\": [{\"name\": \"Alessio\", \"birthday\": \"08/29/1995\", \"location\": \"Rome\"}, {\"name\": \"Sarah\", \"birthday\": \"08/08/??\", \"location\": \"Milwaukee\"}]}\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)\n",
    "\n",
    "print(assistant_message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than defining functions, you can also use Instructor. By default, it's still a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Ben Firshman\",\n",
      "  \"role\": \"Co-founder and CEO\",\n",
      "  \"company\": \"Replicate\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "\n",
    "from pydantic import BaseModel\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class PersonDetail(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "    company: str    \n",
    "\n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=PersonDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"\"\"\n",
    "         Extract Alessio [00:00:00]: Hey everyone, welcome to the Latent Space podcast. This is Alessio, partner and CTO in Residence at Decibel Partners, and I'm joined by my co-host Swyx, founder of Smol AI.\n",
    "\n",
    "                Swyx [00:00:14]: Hey, and today we have Ben Firshman in the studio. Welcome Ben.\n",
    "\n",
    "                Ben [00:00:18]: Hey, good to be here.\n",
    "\n",
    "                Swyx [00:00:19]: Ben, you're a co-founder and CEO of Replicate. Before that, you were most notably founder of Fig, which became Docker Compose. You also did a couple of other things before that, but that's what a lot of people know you for. What should people know about you that, you know, outside of your, your sort of LinkedIn profile?\n",
    "         \"\"\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "assert isinstance(user, PersonDetail)\n",
    "print(user.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4-turbo-preview includes parallel function calling. Instructor still only has \"early access\" for it, but it works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Alessio' role='partner and CTO in Residence' company='Decibel Partners'\n",
      "name='Swyx' role='founder' company='Smol AI'\n",
      "name='Ben Firshman' role='co-founder and CEO' company='Replicate'\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "\n",
    "from typing import Iterable\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)  \n",
    "\n",
    "class PersonDetail(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "    company: str    \n",
    "\n",
    "function_calls = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    response_model=Iterable[PersonDetail],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You must always use tools\"},\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"\"\"\n",
    "         Extract Alessio [00:00:00]: Hey everyone, welcome to the Latent Space podcast. This is Alessio, partner and CTO in Residence at Decibel Partners, and I'm joined by my co-host Swyx, founder of Smol AI.\n",
    "\n",
    "                Swyx [00:00:14]: Hey, and today we have Ben Firshman in the studio. Welcome Ben.\n",
    "\n",
    "                Ben [00:00:18]: Hey, good to be here.\n",
    "\n",
    "                Swyx [00:00:19]: Ben, you're a co-founder and CEO of Replicate. Before that, you were most notably founder of Fig, which became Docker Compose. You also did a couple of other things before that, but that's what a lot of people know you for. What should people know about you that, you know, outside of your, your sort of LinkedIn profile?\n",
    "         \"\"\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "for fc in function_calls:\n",
    "    print(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's SDK also supports parallel function calling. We can re-use the exact same tools definition as before, but simply switch to GPT-4-turbo-preview and it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_people_information\",\n",
    "            \"description\": \"Extract the information for a person. Make sure to use MM/DD/YY formatting for dates.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Name of the person to be extracted.\"\n",
    "                    },\n",
    "                    \"birthday\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Date of birth of the person to be extracted.\"\n",
    "                    },\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Location of the person to be extracted.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name, birthday, location\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0rJeA4rdQXju9ZkyfJVFX7bM', function=Function(arguments='{\"name\": \"Alessio\", \"birthday\": \"08/29/1995\", \"location\": \"Rome\"}', name='extract_people_information'), type='function'), ChatCompletionMessageToolCall(id='call_l7XCtBxmnR54p9YwKl1vZcky', function=Function(arguments='{\"name\": \"Sarah\", \"birthday\": \"08/08/1996\", \"location\": \"Milwaukee\"}', name='extract_people_information'), type='function')]))]\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"You're an assistant that summarizes the information for all people mentioned in the user messages.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"I met Alessio, a guy from Rome whose birthday is on Aug 29th and is 29 years old (we are in 2024 now). I also met Sarah who was born on the 8th of August instead and is from Milwaukee\"})\n",
    "chat_response = chat_completion_request(messages, tools=tools, model='gpt-4-turbo-preview')\n",
    "print(chat_response.choices)\n",
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You're an assistant that summarizes the information for all people mentioned in the user messages.\n",
      "\u001b[0m\n",
      "\u001b[32muser: I met Alessio, a guy from Rome whose birthday is on Aug 29th and is 29 years old (we are in 2024 now). I also met Sarah who was born on the 8th of August instead and is from Milwaukee\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\"name\": \"Alessio\", \"birthday\": \"08/29/1995\", \"location\": \"Rome\"}', name='extract_people_information')\n",
      "\u001b[0m\n",
      "{\"name\": \"Alessio\", \"birthday\": \"08/29/1995\", \"location\": \"Rome\"}\n",
      "{\"name\": \"Sarah\", \"birthday\": \"08/08/1996\", \"location\": \"Milwaukee\"}\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)\n",
    "\n",
    "for tool in assistant_message.tool_calls:\n",
    "    print(tool.function.arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
